\documentclass[11pt]{article}
\usepackage[a4paper,left=16mm, right=16mm, top=20mm, bottom=20mm]{geometry}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{listings} 
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\def\sectionheader#1{\section*{#1}\vskip -0.3cm\hrule\vskip 0.3cm}

\def\image#1#2#3#4
{
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=#4]{#1}
        \caption{#2 \label{#3}}
    \end{figure}
}

\newcommand\fnurl[2]{%
\href{#2}{#1}\footnote{\url{#2}}%
}

\title{Udacity Machine Learning Nanodegree \\ Capstone Project}
\author{Carsten Kr\"uger}
\date{\today}

\begin{document}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\maketitle

\section{Definition}

\subsection{Project Overview}

Machine learning is used in a wide variety of fields today. 
Luca Talenti et al. \cite{malaria} for example used a classification model to predict 
the severity criteria in imported malaria. In this project, machine learning will be used
to build a model that can decide based on the role information of an employee whether
that employee shall have access to a specific resource. 
\\ \\
An employee that has to use a computer in order to fulfill their tasks, needs access 
to certain areas of software programs or access rights to execute actions such as read, 
write or delete a document. While working, employees may encounter that they don't have a 
concrete access right required to perform the task at hand. In those situations a supervisor or an 
administrator has to grant them access. The process of discovering that a certain access 
right is missing and removing that obstacle is both time-consuming and costly.
A model that can predict which access rights are needed based on the current role of an 
employee is therefore relevant.
    
\subsection{Problem Statement}

The problem stems from the {\it Amazon.com Employee Access Challenge Kaggle Competition} 
\cite{kaggleAmazon} and is there described as follows:

{\it ``The objective of this competition is to build a model, learned using 
historical data, that
 will determine an employee's access needs, such that manual access transactions 
 (grants and revokes) are minimized as the employee's attributes change over time. 
 The model will take an employee's role information and a resource code and will return whether 
 or not access should be granted.''}
\\ \\
This is a supervised learning problem because the dataset is labeled. 
Anticipated solution:

\begin{enumerate}
    \item Explore data in order to gain insights.
    \item Train many different binary classification models using standard parameters.
    \item Apply transformations or regularizations.
    \item Compare plain models and transformed models.
    \item Pick the three best models based on the performance metric.
    \item Tweak the chosen models in order to improve model performance.
    \item Evaluate the tweaked models on the test set.
    \item Conclusion
\end{enumerate}

\subsection{Metrics}

To quantify model performance, the area under the ROC curve will be used.
This metric is appropriate for this type of project because it works well
even if the classes are not balanced. Moreover it was the metric of choice
in the herein before mentioned Kaggle competition.
The metric is derived by first constructing the ROC curve and then 
calculating the area under that curve. 

{\it``The ROC curve is created by plotting the true positive rate against the false 
positive rate at various threshold settings''} \cite{rocCurve},
 
where the threshold is a value between 0 and 1 that determines how sure the model needs 
to be in order to classify a data entry as positive (access granted in the problem at hand). 
For example if the threshold was 0.7 the model would have to have calculated a probability 
of at least 70 $\%$ to classify a data entry as positive.

\section{Analysis}

\subsection{Data Exploration}

There are $32769$ entries in the dataset with no missing values. 
Figure \ref{first_5} shows the first five rows in the dataset.

\image{images/dataset_head.png}{Top five rows in the dataset}{first_5}{140mm}

The dataset has ten attributes. All attributes are categorial. 
One attribute called {\tt RESOURCE} holds the ID of the resource 
for which the access has been granted or denied. 
There are $7518$ different resources in the dataset.
The target attribute is called {\tt ACTION}.
The other eight columns provide role information 
for an \fnurl{employee}{https://www.kaggle.com/c/amazon-employee-access-challenge/data}:

\begin{itemize}
    \item {\tt MGR\_ID} - ID of the manager of employee ($4243$ different values)
    \item {\tt ROLE\_ROLLUP\_1} - Role ID of employee ($128$ different values)
    \item {\tt ROLE\_ROLLUP\_2} - Second role ID of employee ($177$ different values)
    \item {\tt ROLE\_DEPTNAME} - Role department description ($449$ different values)
    \item {\tt ROLE\_TITLE} - Role business title ($343$ different values)
    \item {\tt ROLE\_FAMILY} -  Role family description ($67$ different values)
    \item {\tt ROLE\_FAMILY\_DESC} - Extended role family description ($2358$ different values)
    \item {\tt ROLE\_CODE} - Company role code; this code is unique to each role ($343$ different values)
\end{itemize}
\noindent
Because the eight attributes that describe the role of an employee and the resource
attribute are categorial, they will be vectorized. 
This is achieved by using one-hot encoding. For example the {\tt ROLE\_FAMILY}-attribute
has $67$ different categories. Each row in the dataset that has been one-hot encoded 
will contain one entry for each category. The entry will be $1$ (hot) only for the 
entry corresponding to the current role family  and $0$ (cold) for the 
$66$ other role families. This example shows that the number of input attributes will
increase tremendously.

\subsection{Exploratory Visualization}

Figure \ref{histogram} shows that the {\tt ACTION}-attribute is highly unbalanced. 
In fact more than $94 \%$ of the rows have an {\tt ACTION}-attribute 
of $1$ (access granted) whereas only roughly $6 \%$ have a $0$ (access denied).
The accuracy metric is therefore inadequate for this dataset because even
a dumb model that always predicts $1$ would have a very high accuracy.

\image{images/action_histogram.png}{Histogram for target attribute}{histogram}{100mm}

\subsection{Algorithms and Techniques}

First of all it is important to put aside a test set. This set will not be touched until the very end
when all models have been trained and optimized. To generate the test set
\fnurl{stratified shuffle split}{http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html}  
will be used which preserves the percentage of samples for each class.
A preprocessing pipeline will be created, that selects role attributes and applies
one-hot encoding to them. This step is important because, as mentioned before,
the attributes are categorial and two values that are close to each other are not
more similar than two values with a larger distance.
Different binary classification models with standard parameters will be created.
The classifiers trained in this project are Logistic Regression, 
Decision Tree, SVM, Random Forest, AdaBoost and XGBoost.
They will be initialized with a fixed random seed in order to make the results reproducable.
There performance will be measured using scikit learn's 
\fnurl{cross validation score}{http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html} 
function in order to circumvent overfitting. 
The best models will be tweaked by trying different sets of parameters.
The goal is to furhter increase their performance. The best set of hyperparameters
for the different models will be determined by doing a
\fnurl{grid search}{http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html}.
The grid search function will try out all different combinations of 
hyperparameters and values that it gets passed as an argument using cross-validation. 
This is far more convenient than the tedious task of trying out a bunch of hyperparameters manually.
Finally the previously generated test set will be used to determine
whether the final model generalizes well.

\subsection{Benchmark}

An out of the box logistic regression model will be used as the benchmark for 
this project, because the model is fast, simple to implement and to interpret 
and should give far better results than random guessing for the problem at hand.
\\ \\
Because the problems stems from a Kaggle competition, as a secondary benchmark, 
the result of the final solution will be compared to the result of the solution 
of the team that won the competition. 
The submissions to the competition were judged on the 
{\it area under the ROC curve (auc)} metric. 
Therefore this metric will be used to compare the results. 
The winning team got an {\it auc} value 
of $0.92360$, which is an excellent result.

\section{Methodology}

\subsection{Data Preprocessing}

Compared to the samples with a positive
class (access granted) the dataset contains very few samples with a negative class
(access denied). The first preprocessing step is therefore to put aside a test set 
that preserves the percentage of samples for each class. As mentioned before this is 
achieved by using a stratified shuffle split.
If a standard random split had been used to
split the dataset into a training and testing set, it would be possible that
for example the training set would not contain a single negative sample which
would have certainly a negative impact on the performance of the classifiers.
The second preprocessing step is to one-hot encode the predictive attributes.
This is done by using sklearn's
\fnurl{{\it OneHotEncoder}}{http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html}.
This transforms all the categorial attributes to binary attributes and fixes the
issue that the models would assume that two nearby values of a categorial
attribute are more similar than two distant values.

\subsection{Implementation}

The first step is to make some imports and to read the dataset:
\begin{lstlisting}[frame=single]
    import numpy as np
    import pandas as pd
    random_state = 42
    df = pd.read_csv('../data/train.csv')
\end{lstlisting}
    
The second step is to create the stratified training and test sets:

\begin{lstlisting}[frame=single]
    from sklearn.model_selection import StratifiedShuffleSplit
    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=random_state)
    for train_index, test_index in sss.split(df, df['ACTION']):
        train_set, test_set = df.loc[train_index], df.loc[test_index]
\end{lstlisting}

The third step is to extract the labels and the attributes for the training set:

\begin{lstlisting}[frame=single]
    access = train_set.drop('ACTION', axis=1)
    access_labels = train_set['ACTION'].copy()
\end{lstlisting}

The fourth step uses a {\tt DataFrameSelector}:

\begin{lstlisting}[frame=single]
    # DataFrameSelector class, taken from "Hands-On Machine Learning with Scikit-Learn & 
    # Tensorflow by Aurélion Géron (O'Reilly). Copyright 2017 Aurélion Géron, 978-1-491-96229-9, Page 41
    from sklearn.base import BaseEstimator, TransformerMixin
    class DataFrameSelector(BaseEstimator, TransformerMixin):
        def __init__(self, attribute_names):
            self.attribute_names = attribute_names
        def fit(self, X, y=None):
            return self
        def transform(self, X):
            return X[self.attribute_names].values
\end{lstlisting}

With this class a pipeline is created that one-hot encodes the attributes of the 
training set:

\begin{lstlisting}[frame=single]
    # get attributes
    attributes = access.columns.values.tolist()

    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import OneHotEncoder

    # one-hot encode the categorial attributes
    pipeline = Pipeline([
        ('selector', DataFrameSelector(attributes)),
        ('encoder', OneHotEncoder())
    ])
    access_1hot = pipeline.fit_transform(access)
\end{lstlisting}

\subsection{Refinement}

\section{Results}

\subsection{Model Evaluation and Validation}

\subsection{Justification}

\section{Conclusion}

\subsection{Free-Form Visualization}

\subsection{Reflection}

\subsection{Improvement}

\begin{thebibliography}{9}

    \bibitem{malaria}
    L1 logistic regression as a feature selection step for training stable 
    classification trees for the prediction of severity criteria in imported malaria

    \textit{Luca Talenti, Margaux Luck, Anastasia Yartseva, Nicolas Argy, Sandrine Houzé, Cecilia Damon}

    \href{https://arxiv.org/abs/1511.06663}{arXiv:1511.06663 [cs.LG]}

    \bibitem{kaggleAmazon}
    Amazon.com -- Employee Access Challenge 

    \textit{Predict an employee's access needs, given his/her job role.}

    \href{https://www.kaggle.com/c/amazon-employee-access-challenge}
    {https://www.kaggle.com/c/amazon-employee-access-challenge},


    \bibitem{rocCurve}
    Receiver operating characteristic 

    \href{https://en.wikipedia.org/wiki/Receiver_operating_characteristic}
    {https://en.wikipedia.org/wiki/Receiver\_operating\_characteristic}

\end{thebibliography}

\end{document}
    
    
    
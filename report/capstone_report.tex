\documentclass[11pt]{article}
\usepackage[a4paper,left=16mm, right=16mm, top=20mm, bottom=20mm]{geometry}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}

\def\sectionheader#1{\section*{#1}\vskip -0.3cm\hrule\vskip 0.3cm}

\def\image#1#2#3#4
{
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=#4]{#1}
        \caption{#2 \label{#3}}
    \end{figure}
}

\newcommand\fnurl[2]{%
\href{#2}{#1}\footnote{\url{#2}}%
}

\title{Udacity Machine Learning Nanodegree \\ Capstone Project}
\author{Carsten Kr\"uger}
\date{\today}

\begin{document}

\maketitle

\section{Definition}

\subsection{Project Overview}

Machine learning is used in a wide variety of fields today. 
Luca Talenti et al. \cite{malaria} for example used a classification model to predict 
the severity criteria in imported malaria. In this project, machine learning will be used
to build a model that can decide based on the role information of an employee whether
that employee shall have access to a specific resource. 
\\ \\
An employee that has to use a computer in order to fulfill their tasks, needs access 
to certain areas of software programs or access rights to execute actions such as read, 
write or delete a document. While working, employees may encounter that they don't have a 
concrete access right required to perform the task at hand. In those situations a supervisor or an 
administrator has to grant them access. The process of discovering that a certain access 
right is missing and removing that obstacle is both time-consuming and costly.
A model that can predict which access rights are needed based on the current role of an 
employee is therefore relevant.
    
\subsection{Problem Statement}

The problem stems from the {\it Amazon.com Employee Access Challenge Kaggle Competition} 
\cite{kaggleAmazon} and is there described as follows:

{\it ``The objective of this competition is to build a model, learned using 
historical data, that
 will determine an employee's access needs, such that manual access transactions 
 (grants and revokes) are minimized as the employee's attributes change over time. 
 The model will take an employee's role information and a resource code and will return whether 
 or not access should be granted.''}
\\ \\
This is a supervised learning problem because the dataset is labeled. 
Anticipated solution:

\begin{enumerate}
    \item Explore data in order to gain insights.
    \item Train many different binary classification models using standard parameters.
    \item Apply transformations or regularizations.
    \item Compare plain models and transformed models.
    \item Pick the three best models based on the performance metric.
    \item Tweak the chosen models in order to improve model performance.
    \item Evaluate the tweaked models on the test set.
    \item Conclusion
\end{enumerate}

\subsection{Metrics}

To quantify model performance, the area under the ROC curve will be used.
This metric is appropriate for this type of project because it works well
even if the classes are not balanced. Moreover it was the metric of choice
in the herein before mentioned Kaggle competition.
The metric is derived by first constructing the ROC curve and then 
calculating the area under that curve. 

{\it``The ROC curve is created by plotting the true positive rate against the false 
positive rate at various threshold settings''} \cite{rocCurve},
 
where the threshold is a value between 0 and 1 that determines how sure the model needs 
to be in order to classify a data entry as positive (access granted in the problem at hand). 
For example if the threshold was 0.7 the model would have to have calculated a probability 
of at least 70 $\%$ to classify a data entry as positive.

\section{Analysis}

\subsection{Data Exploration}

There are $32769$ entries in the dataset with no missing values. 
Figure \ref{first_5} shows the first five rows in the dataset.

\image{images/dataset_head.png}{Top five rows in the dataset}{first_5}{140mm}

The dataset has ten attributes. All attributes are categorial. 
One attribute called {\tt RESOURCE} holds the ID of the resource 
for which the access has been granted or denied. 
There are $7518$ different resources in the dataset.
The target attribute is called {\tt ACTION}.
The other eight columns provide role information 
for an \fnurl{employee}{https://www.kaggle.com/c/amazon-employee-access-challenge/data}:

\begin{itemize}
    \item {\tt MGR\_ID} - ID of the manager of employee ($4243$ different values)
    \item {\tt ROLE\_ROLLUP\_1} - Role ID of employee ($128$ different values)
    \item {\tt ROLE\_ROLLUP\_2} - Second role ID of employee ($177$ different values)
    \item {\tt ROLE\_DEPTNAME} - Role department description ($449$ different values)
    \item {\tt ROLE\_TITLE} - Role business title ($343$ different values)
    \item {\tt ROLE\_FAMILY} -  Role family description ($67$ different values)
    \item {\tt ROLE\_FAMILY\_DESC} - Extended role family description ($2358$ different values)
    \item {\tt ROLE\_CODE} - Company role code; this code is unique to each role ($343$ different values)
\end{itemize}
\noindent
Because the eight attributes that describe the role of an employee and the resource
attribute are categorial, they will be vectorized. 
This is achieved by using one-hot encoding. For example the {\tt ROLE\_FAMILY}-attribute
has $67$ different categories. Each row in the dataset that has been one-hot encoded 
will contain one entry for each category. The entry will be $1$ (hot) only for the 
entry corresponding to the current role family  and $0$ (cold) for the 
$66$ other role families. This example shows that the number of input attributes will
increase tremendously.


\subsection{Exploratory Visualization}

Figure \ref{histogram} shows that the {\tt ACTION}-attribute is highly unbalanced. 
In fact more than $94 \%$ of the rows have an {\tt ACTION}-attribute 
of $1$ (access granted) whereas only roughly $6 \%$ have a $0$ (access denied).
The accuracy metric is therefore inadequate for this dataset because even
a dumb model that always predicts $1$ would have a very high accuracy.

\image{images/action_histogram.png}{Histogram for target attribute}{histogram}{100mm}

\subsection{Algorithms and Techniques}

First of all it is important to put aside a test set. This set will not be touched until the very end
when all models have been trained and optimized. To generate the test set
\fnurl{stratified shuffle split}{http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html}  
will be used which preserves the percentage of samples for each class.
A preprocessing pipeline will be created, that selects role attributes and applies
one-hot encoding to them. This step is important because, as mentioned before,
the attributes are categorial and two values that are close to each other are not
more similar than two values with a larger distance.
Different binary classification models with standard parameters will be created.
They will be initialized with a fixed random seed in order to make the results reproducable.
There performance will be measured using scikit learn's 
\fnurl{cross validation score}{http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html} 
function in order to circumvent overfitting. 
The best models will be tweaked by trying different sets of parameters.
The goal is to furhter increase their performance.
Finally the previously generated test set will be used to determine
whether the final model generalizes well.

\subsection{Benchmark}

An out of the box logistic regression model will be used as the benchmark for 
this project, because the model is fast, simple to implement and to interpret 
and should give far better results than random guessing for the problem at hand.
\\ \\
Because the problems stems from a Kaggle competition, as a secondary benchmark, 
the result of the final solution will be compared to the result of the solution 
of the team that won the competition. 
The submissions to the competition were judged on the 
{\it area under the ROC curve (auc)} metric. 
Therefore this metric will be used to compare the results. 
The winning team got an {\it auc} value 
of $0.92360$, which is an excellent result.

\section{Methodology}

\subsection{Data Preprocessing}

\subsection{Implementation}

\subsection{Refinement}

\section{Results}

\subsection{Model Evaluation and Validation}

\subsection{Justification}

\section{Conclusion}

\subsection{Free-Form Visualization}

\subsection{Reflection}

\subsection{Improvement}

\begin{thebibliography}{9}

    \bibitem{malaria}
    L1 logistic regression as a feature selection step for training stable 
    classification trees for the prediction of severity criteria in imported malaria

    \textit{Luca Talenti, Margaux Luck, Anastasia Yartseva, Nicolas Argy, Sandrine Houz√©, Cecilia Damon}

    \href{https://arxiv.org/abs/1511.06663}{arXiv:1511.06663 [cs.LG]}

    \bibitem{kaggleAmazon}
    Amazon.com -- Employee Access Challenge 

    \textit{Predict an employee's access needs, given his/her job role.}

    \href{https://www.kaggle.com/c/amazon-employee-access-challenge}
    {https://www.kaggle.com/c/amazon-employee-access-challenge},


    \bibitem{rocCurve}
    Receiver operating characteristic 

    \href{https://en.wikipedia.org/wiki/Receiver_operating_characteristic}
    {https://en.wikipedia.org/wiki/Receiver\_operating\_characteristic}

\end{thebibliography}

\end{document}
    
    
    